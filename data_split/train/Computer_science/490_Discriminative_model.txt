Discriminative models, also called conditional models, are a class of models used in machine learning for modeling the dependence of unobserved (target) variables 
  
    
      
        y
      
    
    {\displaystyle y}
   on observed variables 
  
    
      
        x
      
    
    {\displaystyle x}
  . Within a probabilistic framework, this is done by modeling the conditional probability distribution 
  
    
      
        P
        (
        y
        
          |
        
        x
        )
      
    
    {\displaystyle P(y|x)}
  , which can be used for predicting 
  
    
      
        y
      
    
    {\displaystyle y}
   from 
  
    
      
        x
      
    
    {\displaystyle x}
  .
Discriminative models, as opposed to generative models, do not allow one to generate samples from the joint distribution of observed and target variables. However, for tasks such as classification and regression that do not require the joint distribution, discriminative models can yield superior performance (in part because they have fewer variables to compute). On the other hand, generative models are typically more flexible than discriminative models in expressing dependencies in complex learning tasks. In addition, most discriminative models are inherently supervised and cannot easily support unsupervised learning. Application-specific details ultimately dictate the suitability of selecting a discriminative versus generative model.


== Types ==
Examples of discriminative models used in machine learning include:
Logistic regression, a type of generalized linear regression used for predicting binary or categorical outputs (also known as maximum entropy classifiers)
Support vector machines
Boosting (meta-algorithm)
Conditional random fields
Linear regression
Neural networks
Random forests


== See also ==
Generative model


== References ==